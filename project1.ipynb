{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093bae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from time import time\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bf6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def project1_model():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "# def test():\n",
    "#     net = ResNet18()\n",
    "#     y = net(torch.randn(1, 3, 32, 32))\n",
    "#     print(y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999df676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=512, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=200, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2738cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = project1_model()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "#train_dur_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "#test_dur_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_index = 0\n",
    "    t0 = time()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        # loss = nll(outputs, targets)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_index = batch_idx\n",
    "        # train_loss += loss.item()\n",
    "        train_loss = loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        #print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     #% (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        #print(\"\\n\")\n",
    "    train_loss_list.append(train_loss/(batch_index+1))\n",
    "    train_acc_list.append(100.*correct/total)\n",
    "    print(' Train: Loss: %.6f | Acc: %.3f%% | Dur: %.2fS' \n",
    "          % (train_loss/(batch_index+1), 100.*correct/total, time() - t0))\n",
    "\n",
    "def test(epoch):\n",
    "#     global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_index = 0\n",
    "    t0 = time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # loss = nll(outputs, targets)\n",
    "            batch_index = batch_idx\n",
    "            # test_loss += loss.item()\n",
    "            test_loss = loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            #print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         #% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            #print(\"\\n\")\n",
    "    test_loss_list.append(test_loss/(batch_index+1))\n",
    "    test_acc_list.append(100.*correct/total)\n",
    "    print(' Test:  Loss: %.6f | Acc: %.3f%% | Dur: %.2fS' \n",
    "          % (test_loss/(batch_index+1), 100.*correct/total, time() - t0))\n",
    "\n",
    "    # Save checkpoint.\n",
    "#     acc = 100.*correct/total\n",
    "#     if acc > best_acc:\n",
    "#         print('Saving..')\n",
    "#         state = {\n",
    "#             'net': net.state_dict(),\n",
    "#             'acc': acc,\n",
    "#             'epoch': epoch,\n",
    "#             'train_history': (train_loss_list, train_acc_list, test_loss_list, test_acc_list)\n",
    "#         }\n",
    "#         if not os.path.isdir('checkpoint'):\n",
    "#             os.mkdir('checkpoint')\n",
    "#         torch.save(state, './checkpoint/ckpt_rmsprop.pth')\n",
    "#         best_acc = acc\n",
    "\n",
    "\n",
    "def plot_model(train_loss, train_acc, test_loss, test_acc):\n",
    "    length = len(train_acc)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(range(length), train_acc)\n",
    "    plt.title('Train accuracy vs. epoches')\n",
    "    plt.ylabel('Train accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(range(length), train_loss)\n",
    "    plt.title('Train loss vs. epoches')\n",
    "    plt.ylabel('Train loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(range(length), test_acc)\n",
    "    plt.title('Test accuracy vs. epoches')\n",
    "    plt.ylabel('Test accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(range(length), test_loss)\n",
    "    plt.title('Test loss vs. epoches')\n",
    "    plt.ylabel('Test loss')\n",
    "    plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c8ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.0, 32.062, 35.88, 38.674, 40.974, 43.374, 45.082, 46.856, 48.698, 50.268, 51.932, 52.678, 54.838, 55.492, 56.464, 57.178, 58.19, 59.394, 59.654, 61.142, 61.326, 62.036, 62.26, 63.474, 64.452, 64.942, 65.542, 66.142, 66.562, 67.372, 67.508, 68.338, 68.474, 69.294, 69.736, 70.222, 70.702, 71.172, 71.332, 72.04, 72.244, 72.746, 73.222, 73.11, 73.974, 74.826, 74.744, 75.014, 75.358, 75.64, 76.028, 76.328, 76.434, 77.178, 77.054, 77.986, 77.746, 78.894, 78.536, 79.12, 79.098, 79.412, 79.684, 79.976, 80.204, 80.548, 80.826, 80.964, 81.266, 81.096, 81.564, 81.84, 82.026, 82.514, 82.078, 82.594, 82.852, 83.144, 83.36, 83.274, 83.338, 83.618, 83.926, 84.078, 84.47, 84.716, 84.288, 84.81, 85.1, 85.092, 85.136, 85.774, 85.67, 85.574, 85.768, 85.956, 86.322, 86.272, 86.396, 86.358]\n",
      "[0.07863185882568359, 0.0707058334350586, 0.06798649787902832, 0.06558572769165039, 0.06468032360076904, 0.061038212776184084, 0.057265644073486326, 0.056644749641418454, 0.05576033592224121, 0.05498651027679444, 0.05264454841613769, 0.05257030963897705, 0.04974825382232666, 0.04857631683349609, 0.04753073215484619, 0.048348093032836915, 0.0436748456954956, 0.04462134838104248, 0.04487419128417969, 0.04228043079376221, 0.04050019264221191, 0.040642805099487304, 0.04181492328643799, 0.03955710411071777, 0.03851609706878662, 0.03849510431289673, 0.03793619632720947, 0.037524662017822265, 0.03840357303619385, 0.037106380462646485, 0.03699802160263062, 0.03638580322265625, 0.036912460327148434, 0.03510436773300171, 0.035551464557647704, 0.03355903625488281, 0.033505640029907226, 0.032566561698913574, 0.03406266450881958, 0.029874682426452637, 0.030240447521209718, 0.03020378589630127, 0.029678256511688234, 0.02879125118255615, 0.02906115770339966, 0.02756828784942627, 0.02739781379699707, 0.027682363986968994, 0.025198912620544432, 0.02571577787399292, 0.026360325813293457, 0.025908119678497314, 0.02723557472229004, 0.02587371826171875, 0.02587486743927002, 0.02453281879425049, 0.026128392219543457, 0.024118516445159912, 0.022101948261260985, 0.02383044481277466, 0.021834821701049806, 0.021776952743530274, 0.022092773914337158, 0.02420212507247925, 0.0220889949798584, 0.021226089000701904, 0.022498111724853515, 0.021575477123260498, 0.02141986131668091, 0.021067802906036378, 0.022199227809906005, 0.019723931550979613, 0.01965645670890808, 0.0185335636138916, 0.020763792991638184, 0.018775198459625244, 0.019220219850540163, 0.01922159790992737, 0.019232780933380128, 0.018866034746170043, 0.018120028972625733, 0.019286104440689088, 0.01885881781578064, 0.01834018111228943, 0.01741308331489563, 0.017631022930145263, 0.01713442325592041, 0.016744831800460814, 0.01635852813720703, 0.01761107683181763, 0.01631205916404724, 0.01681686520576477, 0.016832023859024048, 0.015244742631912231, 0.015493625402450561, 0.016354949474334718, 0.017266392707824707, 0.01643863081932068, 0.014935929775238038, 0.01553526520729065]\n"
     ]
    }
   ],
   "source": [
    "print(train_acc_list)\n",
    "print(train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81189086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.47, 33.97, 33.71, 40.18, 41.94, 39.81, 45.23, 45.07, 48.13, 49.38, 51.01, 43.99, 51.95, 54.53, 55.06, 53.9, 57.84, 55.98, 57.95, 56.88, 60.61, 61.95, 61.24, 61.19, 62.33, 63.5, 65.14, 61.19, 65.77, 65.59, 65.18, 64.24, 59.65, 61.63, 63.67, 66.98, 66.23, 67.73, 67.45, 66.38, 68.32, 67.76, 69.04, 71.43, 70.55, 71.78, 67.69, 68.69, 71.08, 70.94, 73.65, 72.5, 69.46, 73.72, 73.45, 73.61, 72.89, 72.87, 76.42, 74.02, 76.48, 75.72, 75.01, 76.05, 77.22, 77.23, 76.04, 76.19, 75.19, 76.65, 77.29, 77.49, 78.73, 76.86, 77.47, 78.62, 77.57, 78.64, 79.18, 79.42, 79.63, 78.95, 78.14, 77.99, 79.66, 80.11, 79.83, 78.99, 78.55, 79.58, 81.01, 79.06, 76.25, 80.91, 79.46, 80.71, 79.1, 79.75, 80.85, 80.27]\n",
      "[0.24788956642150878, 0.17773879766464235, 0.1862744927406311, 0.16267482042312623, 0.15411751270294188, 0.17147183418273926, 0.14832090139389037, 0.15638885498046876, 0.1472830057144165, 0.13727262020111083, 0.13453842401504518, 0.17226266860961914, 0.13430585861206054, 0.13010144233703613, 0.12478911876678467, 0.12576918601989745, 0.1149333357810974, 0.11939616203308105, 0.11592494249343872, 0.12010912895202637, 0.1070931077003479, 0.10311522483825683, 0.10535897016525268, 0.10766539573669434, 0.10264328718185425, 0.09909887909889221, 0.09414167404174804, 0.10955705642700195, 0.09518908262252808, 0.0934921681880951, 0.09512221217155456, 0.10260002613067627, 0.11701548099517822, 0.11461900472640991, 0.09908261895179749, 0.0924258828163147, 0.09599618911743164, 0.08739525675773621, 0.08902118802070617, 0.09499109983444214, 0.08757801651954651, 0.09013639688491822, 0.08629249334335327, 0.07758926153182984, 0.07976871132850646, 0.07839421033859253, 0.09357890486717224, 0.0907427191734314, 0.08478874564170838, 0.08257243037223816, 0.07384616732597352, 0.07763486504554748, 0.09337939620018006, 0.07419365048408508, 0.07834781408309936, 0.07556652426719665, 0.07656546235084534, 0.07852023243904113, 0.0679287850856781, 0.07397759556770325, 0.06753472089767457, 0.06768189072608947, 0.07295039296150208, 0.07027146220207214, 0.06434341669082641, 0.06429337859153747, 0.07066797018051148, 0.06887170076370239, 0.07672905325889587, 0.06737334728240967, 0.06565931439399719, 0.06643133759498596, 0.06023153066635132, 0.07055106163024902, 0.06697786450386048, 0.064005047082901, 0.06374862194061279, 0.06276743412017823, 0.06103031635284424, 0.05824946165084839, 0.05728302001953125, 0.061387276649475096, 0.06454740762710572, 0.06675615310668945, 0.05996033549308777, 0.0579990029335022, 0.061393517255783084, 0.06349796652793885, 0.06127515435218811, 0.06249776482582092, 0.054193198680877686, 0.06271069049835205, 0.0787518322467804, 0.0577720046043396, 0.05865069031715393, 0.0566656231880188, 0.06736825704574585, 0.05729954838752747, 0.05478777289390564, 0.055987733602523806]\n"
     ]
    }
   ],
   "source": [
    "print(test_acc_list)\n",
    "print(test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68658828",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(train_loss_list,train_acc_list,test_loss_list,test_acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
