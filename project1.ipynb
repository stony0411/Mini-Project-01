{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093bae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7261aadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bf6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def project1_model():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "# def test():\n",
    "#     net = ResNet18()\n",
    "#     y = net(torch.randn(1, 3, 32, 32))\n",
    "#     print(y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999df676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2738cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = project1_model()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_index = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        # loss = nll(outputs, targets)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_index = batch_idx\n",
    "        # train_loss += loss.item()\n",
    "        train_loss = loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        print(\"\\n\")\n",
    "    train_loss_list.append(train_loss/(batch_index+1))\n",
    "    train_acc_list.append(100.*correct/total)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_index = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # loss = nll(outputs, targets)\n",
    "            batch_index = batch_idx\n",
    "            # test_loss += loss.item()\n",
    "            test_loss = loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            print(\"\\n\")\n",
    "    test_loss_list.append(test_loss/(batch_index+1))\n",
    "    test_acc_list.append(100.*correct/total)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'train_history': (train_loss_list, train_acc_list, test_loss_list, test_acc_list)\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt_rmsprop.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "0 391 Loss: 2.418 | Acc: 10.156% (13/128)\n",
      "\n",
      "\n",
      "1 391 Loss: 1.173 | Acc: 9.375% (24/256)\n",
      "\n",
      "\n",
      "2 391 Loss: 0.758 | Acc: 10.677% (41/384)\n",
      "\n",
      "\n",
      "3 391 Loss: 0.582 | Acc: 10.938% (56/512)\n",
      "\n",
      "\n",
      "4 391 Loss: 0.449 | Acc: 12.500% (80/640)\n",
      "\n",
      "\n",
      "5 391 Loss: 0.381 | Acc: 11.589% (89/768)\n",
      "\n",
      "\n",
      "6 391 Loss: 0.319 | Acc: 11.496% (103/896)\n",
      "\n",
      "\n",
      "7 391 Loss: 0.272 | Acc: 12.109% (124/1024)\n",
      "\n",
      "\n",
      "8 391 Loss: 0.240 | Acc: 12.674% (146/1152)\n",
      "\n",
      "\n",
      "9 391 Loss: 0.221 | Acc: 13.438% (172/1280)\n",
      "\n",
      "\n",
      "10 391 Loss: 0.199 | Acc: 13.565% (191/1408)\n",
      "\n",
      "\n",
      "11 391 Loss: 0.185 | Acc: 13.932% (214/1536)\n",
      "\n",
      "\n",
      "12 391 Loss: 0.168 | Acc: 14.303% (238/1664)\n",
      "\n",
      "\n",
      "13 391 Loss: 0.151 | Acc: 14.955% (268/1792)\n",
      "\n",
      "\n",
      "14 391 Loss: 0.140 | Acc: 15.365% (295/1920)\n",
      "\n",
      "\n",
      "15 391 Loss: 0.124 | Acc: 16.016% (328/2048)\n",
      "\n",
      "\n",
      "16 391 Loss: 0.120 | Acc: 16.268% (354/2176)\n",
      "\n",
      "\n",
      "17 391 Loss: 0.115 | Acc: 16.536% (381/2304)\n",
      "\n",
      "\n",
      "18 391 Loss: 0.110 | Acc: 16.694% (406/2432)\n",
      "\n",
      "\n",
      "19 391 Loss: 0.100 | Acc: 17.070% (437/2560)\n",
      "\n",
      "\n",
      "20 391 Loss: 0.096 | Acc: 17.374% (467/2688)\n",
      "\n",
      "\n",
      "21 391 Loss: 0.094 | Acc: 17.507% (493/2816)\n",
      "\n",
      "\n",
      "22 391 Loss: 0.090 | Acc: 17.799% (524/2944)\n",
      "\n",
      "\n",
      "23 391 Loss: 0.084 | Acc: 17.839% (548/3072)\n",
      "\n",
      "\n",
      "24 391 Loss: 0.077 | Acc: 18.250% (584/3200)\n",
      "\n",
      "\n",
      "25 391 Loss: 0.076 | Acc: 18.510% (616/3328)\n",
      "\n",
      "\n",
      "26 391 Loss: 0.076 | Acc: 18.461% (638/3456)\n",
      "\n",
      "\n",
      "27 391 Loss: 0.069 | Acc: 18.638% (668/3584)\n",
      "\n",
      "\n",
      "28 391 Loss: 0.068 | Acc: 18.804% (698/3712)\n",
      "\n",
      "\n",
      "29 391 Loss: 0.066 | Acc: 18.958% (728/3840)\n",
      "\n",
      "\n",
      "30 391 Loss: 0.063 | Acc: 19.128% (759/3968)\n",
      "\n",
      "\n",
      "31 391 Loss: 0.060 | Acc: 19.434% (796/4096)\n",
      "\n",
      "\n",
      "32 391 Loss: 0.058 | Acc: 19.650% (830/4224)\n",
      "\n",
      "\n",
      "33 391 Loss: 0.056 | Acc: 19.899% (866/4352)\n",
      "\n",
      "\n",
      "34 391 Loss: 0.055 | Acc: 20.067% (899/4480)\n",
      "\n",
      "\n",
      "35 391 Loss: 0.054 | Acc: 20.269% (934/4608)\n",
      "\n",
      "\n",
      "36 391 Loss: 0.051 | Acc: 20.355% (964/4736)\n",
      "\n",
      "\n",
      "37 391 Loss: 0.049 | Acc: 20.477% (996/4864)\n",
      "\n",
      "\n",
      "38 391 Loss: 0.048 | Acc: 20.773% (1037/4992)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8ca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
